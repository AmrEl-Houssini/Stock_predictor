{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fast_Api_Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g40XoNmTHnue"
      },
      "source": [
        "# Install necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnFISMxDu_Gn"
      },
      "source": [
        "!pip install uvicorn\n",
        "!pip install fastapi\n",
        "!pip install nest_asyncio\n",
        "!pip install pystan\n",
        "!pip install prophet\n",
        "!pip install pyngrok \n",
        "!pip install pmdarima\n",
        "!pip install -v scikit-learn==0.23.2\n",
        "!pip install yfinance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkgmqFsAHrYp"
      },
      "source": [
        "# Importations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cTuI442vbAC"
      },
      "source": [
        "# for FastAPI\n",
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "import pydantic\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "# for FBprophet\n",
        "from datetime import *\n",
        "import yfinance as yf\n",
        "yf.pdr_override()\n",
        "import pandas_datareader.data as pdr\n",
        "import pandas as pd\n",
        "import holidays\n",
        "from prophet import Prophet\n",
        "# for arima\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import pmdarima as pm\n",
        "# for LSTM\n",
        " \n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "# for transformer\n",
        "from utils.Time2Vector import Time2Vector\n",
        "from utils.Attention import MultiAttention, SingleAttention\n",
        "from utils.Encoder import TransformerEncoder\n",
        "from tensorflow import keras\n",
        "import warnings\n",
        "nest_asyncio.apply()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-7cRd_zIRR4"
      },
      "source": [
        "# Indicator value \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nRWfqfOvhJQ"
      },
      "source": [
        "def indicator(reg_pred,arima_pred,lstm_pred,prophet_pred,trans_pred,real):\n",
        "  '''\n",
        "    Decision making based on specific formula and models predictions\n",
        "    Args:\n",
        "        (float) Regression prediciton - the predcition of Ensemble Regression Models\n",
        "        (float) Arima prediciton - the predcition of Arima Model\n",
        "        (float) LSTM prediciton - the predcition of LSTM Model\n",
        "        (float) Prophet prediciton - the predcition of Prophet Model\n",
        "        (float) Transformer prediciton - the predcition of Tranformer Model\n",
        "        (float) Real - the value of Close in the last day\n",
        "  Returns:\n",
        "      (Array) Decision -array of values of [-1,0,1] \n",
        "  '''\n",
        "  # Fromula\n",
        "  percent=real*0.5/100\n",
        "\n",
        "  predictions=[reg_pred,arima_pred,lstm_pred,prophet_pred,trans_pred]\n",
        "  \n",
        "  decisions=[]\n",
        "  for i in predictions:\n",
        " \n",
        "    if i>real+percent:\n",
        "      action=1\n",
        "\n",
        "    elif i<real-percent:\n",
        "      action=-1\n",
        "\n",
        "    else:\n",
        "      action=0\n",
        "    \n",
        "    decisions.append(action)\n",
        "  \n",
        "  return decisions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNMOn5iQv3Wj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def d3_scale(data, out_range=(0, 1)):\n",
        "  '''\n",
        "    Scale values from 0 to 1  \n",
        "    Args:\n",
        "        (float) data - The unscaled data \n",
        "        (tuple) data - The range of the new scaled data \n",
        "        \n",
        "  Returns:\n",
        "      (Array) array that has values from 0 into 1  '''\n",
        "  domain = [np.min(data, axis=0), np.max(data, axis=0)]\n",
        "\n",
        "  def interp(x):\n",
        "      return out_range[0] * (1.0 - x) + out_range[1] * x\n",
        "\n",
        "  def uninterp(x):\n",
        "      b = 0\n",
        "      if (domain[1] - domain[0]) != 0:\n",
        "          b = domain[1] - domain[0]\n",
        "      else:\n",
        "          b =  1.0 / domain[1]\n",
        "      return (x - domain[0]) / b\n",
        "\n",
        "  return interp(uninterp(data))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7maY0eTIbcZ"
      },
      "source": [
        "# Models used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLakoVKkv5CV"
      },
      "source": [
        "def prophet (ticker):\n",
        "  \"\"\"\n",
        "  Forcasting using prophet ! by Getting the desired data from yahoo, then doing some data manipulation, then the comes the prophet's turn\n",
        "  Args:\n",
        "      (str) ticket - the ticker of desired dataset (company)\n",
        "  Returns:\n",
        "      (float) prophet_output - the model out-put (the prediction of the next day)\n",
        "  \"\"\"\n",
        "\n",
        "  # data_gathering\n",
        "  df = pdr.get_data_yahoo(ticker, start='2015-01-01')\n",
        "\n",
        "  # data manipulation\n",
        "  holiday = pd.DataFrame([])\n",
        "  for date, name in sorted(holidays.UnitedStates(years=[2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]).items()):\n",
        "      holiday = holiday.append(pd.DataFrame({'ds': date, 'holiday': \"US-Holidays\"}, index=[0]), ignore_index=True)\n",
        "  holiday['ds'] = pd.to_datetime(holiday['ds'], format='%Y-%m-%d', errors='ignore')\n",
        "\n",
        "  # data frame modification to be accepted by prophet\n",
        "  data = df['Close'].reset_index()\n",
        "  data.columns = ['ds', 'y']\n",
        "\n",
        "  # model building\n",
        "  m = Prophet(holidays=holiday,seasonality_mode='additive', changepoint_prior_scale = 0.1, seasonality_prior_scale=0.01)\n",
        "  m.fit(data)\n",
        "\n",
        "  # model predictions\n",
        "  future = m.make_future_dataframe(periods=1)\n",
        "  model_prediction = m.predict(future) \n",
        "  prophet_prediction = float(model_prediction[ 'yhat'][-1:])\n",
        "  return prophet_prediction\n",
        "\n",
        "\n",
        "def arima(ticker):\n",
        "  \"\"\"\n",
        "  Forcasting using ARIMA ! by Getting the desired data from yahoo, \n",
        "  then finding the best order of arima params then the comes the ARIMA's turn\n",
        "  Args:\n",
        "      (str) ticket - the ticker of desired dataset (company)\n",
        "  Returns:\n",
        "      (float) arima_output - the model out-put (the prediction of the next day)\n",
        "      (float) diff - the model output - today's price (the diff between tomorrow's prediction and today's real value)\n",
        "  \"\"\"\n",
        "    \n",
        "  # data gathering\n",
        "  df = pdr.get_data_yahoo(ticker, start='2016-01-01')\n",
        "  df.index = pd.to_datetime(df.index, format=\"%Y/%m/%d\")\n",
        "  df = pd.Series(df['Close'])\n",
        "  last_day=df[-1]\n",
        "\n",
        "  # finding the best order\n",
        "  auto_order = pm.auto_arima(df, start_p=0, start_q=0, test='adf', max_p=3, max_q=3, m=1,d=None,seasonal=False   \n",
        "                    ,start_P=0,D=0, trace=True,error_action='ignore',suppress_warnings=True,stepwise=True)\n",
        "  best_order = auto_order.order\n",
        "\n",
        "  # model fitting\n",
        "  model = ARIMA(df, order=best_order)\n",
        "  model_fit = model.fit(disp=0)\n",
        "  arima_prediction ,se, conf = model_fit.forecast(1)\n",
        "  \n",
        "  diff = arima_prediction - last_day\n",
        "  \n",
        "  return arima_prediction , diff\n",
        "\n",
        "\n",
        "def lstm(data_set):\n",
        "  \"\"\"\n",
        "  Getting the desired data from yahoo, then doing some data manipulation such as data\n",
        "  reshaping\n",
        "  Args:\n",
        "      (str) data_set - the ticker of desired dataset (company)\n",
        "  Returns:\n",
        "      (float) diff_prediction - the model out-put (the prediction of the next day)\n",
        "      (float) real_prediction - the model output + today's price (real price of tomorrow)\n",
        "  \"\"\"\n",
        "\n",
        "  # data gathering\n",
        "  df = pdr.get_data_yahoo(data_set, start=date.today() - timedelta(100))\n",
        "\n",
        "  # data manipulation\n",
        "\n",
        "  # creating a new df with Xt - Xt-1 values of the close prices (most recent 60 days)\n",
        "  close_df = df['2012-01-01':].reset_index()['Close'][-61:]\n",
        "  close_diff = close_df.diff().dropna()\n",
        "  data = np.array(close_diff).reshape(-1, 1)\n",
        "\n",
        "  # reshaping the data to 3D to be accepted by our LSTM model\n",
        "  model_input = np.reshape(data, (1, 60, 1))\n",
        "\n",
        "  # loading the model and predicting\n",
        "  loaded_model = load_model(\"lstm_f_60.hdf5\")\n",
        "  model_prediction = float(loaded_model.predict(model_input))\n",
        "  real_prediction = model_prediction + df['Close'][-1]\n",
        "  \n",
        "\n",
        "  return model_prediction, real_prediction\n",
        "\n",
        "\n",
        "def Regression(ticker):\n",
        "  \"\"\"\n",
        "  Forcasting using an ensambled model between SVR, Ridge and Linear regression! by Getting the desired data from yahoo, \n",
        "  then doing some data manipulation\n",
        "  Args:\n",
        "      (str) ticket - the ticker of desired dataset (company)\n",
        "  Returns:\n",
        "      (float) arima_output - the model out-put (the prediction of the next day)\n",
        "      (float) diff - the model output - today's price (the diff between tomorrow's prediction and today's real value)\n",
        "  \"\"\"\n",
        "  start_date = datetime.now() - timedelta(7)\n",
        "  start_date = datetime.strftime(start_date, '%Y-%m-%d')\n",
        "\n",
        "  df = pdr.get_data_yahoo(ticker, start=start_date)  # read data\n",
        "  df.drop('Volume', axis='columns', inplace=True)\n",
        "\n",
        "  if df.index[-1]==datetime.now().strftime('%Y-%m-%d') :\n",
        "    df=df.iloc[-2:]\n",
        "  else :\n",
        "    df =df.iloc[-1:]\n",
        "  X = df[['High', 'Low', 'Open', 'Adj Close']]  # input columns\n",
        "  y = df[['Close']]  # output column\n",
        "  input = X\n",
        "  loaded_model = pickle.load(open('regression_model.pkl', 'rb'))\n",
        "  reg_prediction = loaded_model.predict(input)\n",
        "  reg_diff=reg_prediction-df.Close[-1]\n",
        "\n",
        "  return  reg_prediction,reg_diff\n",
        "\n",
        "def Transformer(ticker):\n",
        "  \"\"\"\n",
        "  Getting the desired data from yahoo and doing some  data manipulation then forcasting with trasformer architecture using the last 32 days\n",
        "  Args:\n",
        "      (str) data_set - the ticker of desired dataset (company)\n",
        "  Returns:\n",
        "      (float) trans_difference - the model out-put - today's price\n",
        "      (float) trans_prediction - the model output \n",
        "  \"\"\"\n",
        "  seq_len = 32\n",
        "\n",
        "  start_date = datetime.now() - timedelta(48)\n",
        "  start_date = datetime.strftime(start_date, '%Y-%m-%d')\n",
        "\n",
        "  df = pdr.get_data_yahoo(ticker, start=start_date)\n",
        "\n",
        "  df.drop('Volume', axis=1, inplace=True)\n",
        "\n",
        "  # df[df.columns] = scaler.fit_transform(df)\n",
        "  df = df[['High', 'Low', 'Open', 'Adj Close', 'Close']]\n",
        "\n",
        "  '''Create training, validation and test split'''\n",
        "\n",
        "  test_data = df.values\n",
        "\n",
        "  # Test data\n",
        "  X_test, y_test = [], []\n",
        "  for i in range(seq_len, len(test_data)):\n",
        "      X_test.append(test_data[i - seq_len:i])\n",
        "      y_test.append(test_data[:, 4][i])\n",
        "  X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "  custom_objects = {\"Time2Vector\": Time2Vector,\n",
        "                    \"MultiAttention\": MultiAttention,\n",
        "                    'TransformerEncoder': TransformerEncoder}\n",
        "  with keras.utils.custom_object_scope(custom_objects):\n",
        "      final_model = load_model('Transformer+TimeEmbedding.hdf5')\n",
        "\n",
        "  trans_prediction = float(final_model.predict(X_test)[-1])\n",
        "  trans_difference = trans_prediction - df.Close[-1]\n",
        "\n",
        "  return trans_prediction, trans_difference\n",
        "\n",
        "def real (ticker):\n",
        "  \"this functions handles the logical error that happens if the app runs in weekends, cause the stock market is closed and no data for weekends\"\n",
        "  \n",
        "  start_date = datetime.now() - timedelta(10)\n",
        "  start_date = datetime.strftime(start_date, '%Y-%m-%d')\n",
        "\n",
        "  df = pdr.get_data_yahoo(ticker, start=start_date)  # read data\n",
        "  df.drop('Volume', axis='columns', inplace=True)\n",
        "\n",
        "  if df.index[-1]==datetime.now().strftime('%Y-%m-%d') :\n",
        "    close=df.Close[-2]\n",
        "  \n",
        "  else :\n",
        "    close =df.Close[-1]\n",
        "  \n",
        "  return close\n",
        " \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ain0UKqILUbj"
      },
      "source": [
        "# Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6tnr6RpEv7BA"
      },
      "source": [
        "app = FastAPI()\n",
        "\n",
        "\n",
        "@app.get('/')\n",
        "def index():\n",
        "    return {'message': 'This is your fav stock predictor!'}\n",
        "\n",
        "\n",
        "@app.post('/predict')\n",
        "async def predict_price(data: str):\n",
        "  \"\"\"\n",
        "  generating the most possible accurate decision to buy or sell based on models predictions and the voting technique,\n",
        "  we only now support F ticker (ford motors stock)\n",
        "  Args:\n",
        "      (str) data_set - the ticker of desired dataset (company)\n",
        "  Returns:\n",
        "      (int) final_decision - the decision value that will be presented on an indicatore scaled from 1 to 10 (sell 1-3, neutral 4-7, buy 8-10)\n",
        "  \"\"\"\n",
        "    if data == 'F':\n",
        "      prophet_prediction = float(prophet(data))\n",
        "      arima_prediction, diff = arima(data)\n",
        "      model_prediction, lstm_prediction = lstm(data)\n",
        "      reg_prediction,reg_diff = Regression(data)\n",
        "      trans_prediction, trans_difference = Transformer(data)\n",
        "      close=real(data)\n",
        "      \n",
        "      indicators=np.array(indicator(reg_prediction[0],arima_prediction[0]\n",
        "                                    ,lstm_prediction,prophet_prediction\n",
        "                                    ,trans_prediction,close))\n",
        "      weights=np.array([0.3,0.3,0.3,0.05,0.05])\n",
        "      \n",
        "      \n",
        "      final_decision=indicators*weights\n",
        "      final_decision=final_decision.sum()\n",
        "      final_decision=final_decision.item(0)\n",
        "      decision_array=np.array([-1,final_decision,1],dtype=np.float)\n",
        "      decision_array=d3_scale(decision_array)\n",
        "      final_decision=round(decision_array[1],1)*10\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "      return {\n",
        "        'Decision': final_decision\n",
        "        \n",
        "            }\n",
        "\n",
        "    else:\n",
        "      return {\"the ticker not supported yet\"}\n",
        "\n",
        "    \n",
        "\n",
        "# App startup\n",
        "ngrok_tunnel = ngrok.connect(8090)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8090)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}